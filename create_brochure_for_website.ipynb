{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cb23e957-c0be-4bd1-b907-6b68d26d19d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import requests \n",
    "import json\n",
    "from typing import List\n",
    "from dotenv import load_dotenv\n",
    "from bs4 import BeautifulSoup\n",
    "from IPython.display import Markdown, display, update_display\n",
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b55d4b1c-ab70-43b7-b6ee-fd0dfb11f7fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the key seem to be correct\n"
     ]
    }
   ],
   "source": [
    "#Loading the openai api key\n",
    "path = load_dotenv()\n",
    "api_key = os.getenv(\"Openai_API_Key\")\n",
    "if api_key[:8]!=\"sk-proj-\" : \n",
    "    print(\"invalide key \")\n",
    "if api_key.strip()!=api_key:\n",
    "    print(\"invalide key maybe there is a space at start and/or end\")\n",
    "else : \n",
    "    print(\"the key seem to be correct\")\n",
    "\n",
    "MODEL =\"gpt-4o-mini\"\n",
    "openai = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "454472b4-5606-4251-8a27-70436ac6e44f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The Website class is used for web scraping, parsing data, and extracting text and relevant links.\n",
    "\n",
    "class website :\n",
    "        \"\"\"\n",
    "    A class for web scraping, parsing HTML, and extracting relevant text and links from a given URL.\n",
    "\n",
    "    Attributes:\n",
    "    - url (str): The website URL.\n",
    "    - title (str): The title of the webpage.\n",
    "    - body (str): The raw HTML content of the page.\n",
    "    - links (list[str]): A list of extracted hyperlinks from the page.\n",
    "    - text (str): The cleaned text content of the webpage, excluding scripts, styles, images, and inputs.\n",
    "\n",
    "    Methods:\n",
    "    - get_contents(): Returns a formatted string containing the webpage title and text content.\n",
    "    \"\"\"\n",
    "    url : str\n",
    "    title : str\n",
    "    body : str\n",
    "    links : list[str]\n",
    "    text : str\n",
    "    def __init__(self, url):\n",
    "        self.url = url\n",
    "        response = requests.get(url)\n",
    "        self.body = response.content\n",
    "        soup = BeautifulSoup(self.body,'html.parser')\n",
    "        self.title = soup.title.text if soup.title else \"there is no title\"\n",
    "        if soup.body:\n",
    "            for irelevant in soup.body([\"script\",\"style\",\"img\",\"input\"]):\n",
    "                irelevant.decompose()\n",
    "            self.text = soup.body.get_text(separator=\"\\n\", strip=True)\n",
    "        else : \n",
    "            self.text = \"\"\n",
    "        links = [link.get(\"href\") for link in soup.find_all(\"a\")]\n",
    "        self.links = [link for link in links if link]\n",
    "    def get_contents(self):\n",
    "        return f\"Webpage Title :\\n{self.title}\\nWebpage Contents :\\n{self.text}\\n\\n\"\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9634c910-d45b-42cf-85bb-49d623efe705",
   "metadata": {},
   "source": [
    "#Use a call to gpt-4o-mini to Figure out which links are relevant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "faf63ca7-65e9-4ee4-b667-007b38fe1006",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generate a system prompt\n",
    "link_system_prompt = \"You are provided with a list of links found on a webpage. \\\n",
    "You are able to decide which of the links would be most relevant to include in a brochure about the company, \\\n",
    "such as links to an About page, or a Company pagen or Careers/jobs pages.\\n\"\n",
    "link_system_prompt +=\"You should respond in JSON as in this example:\"\n",
    "link_system_prompt += \"\"\"\n",
    "\"links\" : [\n",
    "            {\"type\":\"about page\",\"url\":\"https://full.url/goes/here/about\"},\n",
    "            {\"type\":\"careers page\",\"url\":\"https://another.full.url/goes/here/about\"}\n",
    "            ]\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6975e12b-cfd3-4913-8080-8018b0151022",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generate a user prompt \n",
    "\n",
    "def get_links_user_prompt(website):\n",
    "        \"\"\"\n",
    "    Generates a user prompt for the AI model to filter relevant web links.\n",
    "\n",
    "    Parameters:\n",
    "    website (object): An object containing website details, including `url` and `links`.\n",
    "\n",
    "    Returns:\n",
    "    str: A formatted prompt listing the website links and asking the AI to select relevant ones in JSON format.\n",
    "    \"\"\"\n",
    "    user_prompt = f\"Here is the list of links on the website of {website.url}-\"\n",
    "    user_prompt += f\"please deicde which of these are relevant web links for a brochure about company, respond with the full https URL in JSON format. \\\n",
    "Do not include Terms of Service, Privacy, email links.\\n\"\n",
    "    user_prompt +=\"Links (some might be relative links):\\n\"\n",
    "    user_prompt +=\"\\n\".join(website.links)\n",
    "    return user_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e058e9d6-d03e-464c-b51d-646f3b7f2db6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_links(url):\n",
    "    \"\"\"Extracts relevant links from the given website URL and formats them into a structured JSON format using an AI model.\n",
    "\n",
    "    Parameters:\n",
    "    url (str): The website URL from which links need to be extracted.\n",
    "\n",
    "    Returns:\n",
    "    dict: A JSON object containing the selected relevant links.\"\"\"\n",
    "    ed = website(url)\n",
    "    completion = openai.chat.completions.create(\n",
    "        model=MODEL,\n",
    "        messages=[{\"role\":\"system\", \"content\":link_system_prompt},\n",
    "                {\"role\":\"user\", \"content\":get_links_user_prompt(ed)}\n",
    "                 ],\n",
    "        response_format={\"type\":\"json_object\"}\n",
    "    )\n",
    "    result = completion.choices[0].message.content\n",
    "    return json.loads(result)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9582c7df-52a0-42f3-ac22-663f6f8a6fab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'links': [{'type': 'about page', 'url': 'https://www.anthropic.com/company'},\n",
       "  {'type': 'careers page', 'url': 'https://www.anthropic.com/careers'},\n",
       "  {'type': 'team page', 'url': 'https://www.anthropic.com/team'},\n",
       "  {'type': 'research page', 'url': 'https://www.anthropic.com/research'},\n",
       "  {'type': 'news page', 'url': 'https://www.anthropic.com/news'}]}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_links('https://anthropic.com')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9995738b-f263-4e39-9e92-6b2c3d09fc8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_details(url): \n",
    "    result = \"Landing page:\\n\"\n",
    "    result += website(url).get_contents()\n",
    "    links = get_links(url)\n",
    "    for link in links[\"links\"] : \n",
    "        result += f\"\\n\\n{link['type']}\\n\"\n",
    "        result += website(link['url']).get_contents()\n",
    "    return result   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "9a42bf38-d90a-4689-bade-babc4bbaa9c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"You are an assistant that analyzes the contents of several relevant pages from a company website \\\n",
    "and creates a short brochure about the company for prospective customers, investors and recruits. Respond in markdown.\\\n",
    "Include details of company culture, customers and careers/jobs if you have the information.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "055eec42-3dec-4921-90d0-bd81e171c864",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_brochure_user_prompt(company_name, url):\n",
    "        \"\"\"\n",
    "    Retrieves and compiles details from a website's landing page and its relevant links.\n",
    "\n",
    "    Parameters:\n",
    "    url (str): The main website URL.\n",
    "\n",
    "    Returns:\n",
    "    str: A formatted string containing the content of the landing page followed by the extracted content from relevant links.\n",
    "    \"\"\"\n",
    "    user_prompt = f\"You are looking at a company called: {company_name}\\n\"\n",
    "    user_prompt += f\"Here are the contents of its landing page and other relevant pages; use this information to build a short brochure of the company in markdown.\\n\"\n",
    "    user_prompt += get_all_details(url)\n",
    "    user_prompt = user_prompt[:5_000] # Truncate if more than 5,000 characters\n",
    "    return user_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "834b0f0b-31a3-4d41-b2fc-63cde9bac8f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_brochure(company_name, url):\n",
    "        \"\"\"\n",
    "    Generates a brochure for a company using AI by processing its website content.\n",
    "\n",
    "    Parameters:\n",
    "    - company_name (str): The name of the company for which the brochure is being created.\n",
    "    - url (str): The website URL of the company.\n",
    "\n",
    "    Returns:\n",
    "    None: This function streams the generated brochure content and displays it dynamically in a notebook environment.\n",
    "    \"\"\"\n",
    "    stream = openai.chat.completions.create(\n",
    "        model=MODEL,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\", \"content\": get_brochure_user_prompt(company_name, url)}\n",
    "          ],\n",
    "        stream= True\n",
    "    )\n",
    "    response = \"\"\n",
    "    display_handle = display(Markdown(\"\"),display_id=True)\n",
    "    for chunk in stream: \n",
    "        response += chunk.choices[0].delta.content or ''\n",
    "        update_display(Markdown(response), display_id=display_handle.display_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "abebb77d-9c59-4dfa-bf02-8befd844b356",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "# Hugging Face Company Brochure\n",
       "\n",
       "## Welcome to Hugging Face!\n",
       "**The AI community building the future.**  \n",
       "Hugging Face is a collaborative platform designed for the machine learning community to create, discover, and share models, datasets, and applications. Our mission is to accelerate the development of artificial intelligence and empower creators and innovators in the field.\n",
       "\n",
       "---\n",
       "\n",
       "## Our Offerings\n",
       "\n",
       "### **Models, Datasets, and Spaces**\n",
       "- **1M+ Models:** Explore a vast repository of pre-trained machine learning models for various tasks.\n",
       "- **250k+ Datasets:** A rich collection of datasets catering to different AI needs, enhancing research and development.\n",
       "- **Applications:** Over 400k applications are available, empowering developers to innovate with ease.\n",
       "\n",
       "### **Enterprise Solutions**\n",
       "Hugging Face offers enterprise-grade solutions tailored for organizations, including:\n",
       "- **Comprehensive Compute Options:** Deploy optimized inference endpoints; start at just $0.60/hour for GPU.\n",
       "- **Dedicated Support:** Enterprise packages provide priority support, single sign-on, and secure access controls, starting at $20/user/month.\n",
       "\n",
       "### **Open Source Community**\n",
       "Our commitment to open source is evident through:\n",
       "- **Transformers Library:** 139,097 implementations for Pytorch, TensorFlow, and JAX.\n",
       "- **Diffusers and Tokenizers:** Powerful tools for image/audio generation and data processing, serving thousands of users.\n",
       "\n",
       "---\n",
       "\n",
       "## Company Culture \n",
       "\n",
       "At Hugging Face, we foster a *collaborative and supportive environment* where everyone is encouraged to innovate and share ideas. We believe in the power of community and strive to create a culture where **diversity** and **inclusion** are celebrated. Every team member is empowered to contribute to the collective knowledge and growth of the AI community.\n",
       "\n",
       "---\n",
       "\n",
       "## Customers and Collaborations\n",
       "\n",
       "With over **50,000 organizations** utilizing our platform, Hugging Face serves a wide range of customers from startups to Fortune 500 companies including:\n",
       "- **Amazon Web Services**\n",
       "- **Microsoft**\n",
       "- **Google**\n",
       "- **Intel**\n",
       "\n",
       "We aim to provide tools and solutions that scale across industries, enhancing productivity and advancing AI research.\n",
       "\n",
       "---\n",
       "\n",
       "## Careers at Hugging Face \n",
       "\n",
       "Join us in shaping the future of AI! At Hugging Face, we value creativity, passion, and the desire to make a difference. Our team is diverse and dedicated to pushing boundaries in machine learning. We offer various roles across different functions, right from engineering to community engagement.\n",
       "\n",
       "### Current Openings:\n",
       "Visit our careers page for available positions to become a part of our vibrant community!\n",
       "\n",
       "---\n",
       "\n",
       "## Connect with Us\n",
       "Follow our journey and stay updated:\n",
       "- [GitHub](https://github.com/huggingface)\n",
       "- [Twitter](https://twitter.com/huggingface)\n",
       "- [LinkedIn](https://www.linkedin.com/company/huggingface/)\n",
       "- [Discord](https://discord.gg/huggingface)\n",
       "\n",
       "**Hugging Face** – Together, we build the future of AI. ✨ \n",
       "\n",
       "--- \n",
       "\n",
       "For more information, visit our website: [www.huggingface.co](https://huggingface.co)"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "create_brochure(\"HuggingFace\", \"https://huggingface.com\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "f9c255ef-2fce-482b-9b51-2e4532f8d19f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "2+2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55e20399-b553-4afb-83ca-9f53b0b4b474",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
