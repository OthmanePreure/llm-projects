{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eviZkz1VJgqh"
      },
      "outputs": [],
      "source": [
        "from openai import OpenAI\n",
        "import gradio\n",
        "import re\n",
        "import os\n",
        "from dotenv import load_dotenv\n",
        "from IPython.display import Markdown, display, update_display\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dg7AYNAbLGRR"
      },
      "outputs": [],
      "source": [
        "os.environ['PATH']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "tbjc1gPiKIsS"
      },
      "outputs": [],
      "source": [
        "load_dotenv()\n",
        "os.environ['OPENAI_API_KEY'] = os.getenv('OPENAI_API_KEY')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "ALKQjpy2L4AM"
      },
      "outputs": [],
      "source": [
        "client = OpenAI()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "8bJtTwTPN_qI"
      },
      "outputs": [],
      "source": [
        "system_cpp_prompt = \"\"\"\n",
        "You are an expert in converting Python code to C++. You are highly skilled in understanding Python syntax and logic, and you are capable of\n",
        "translating that into efficient, well-structured C++ code while ensuring it maintains the same functionality and behavior.\n",
        "Please carefully analyze the provided Python code and provide an accurate and optimized C++ translation.\"\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "id": "wee6-wkdQ4s-"
      },
      "outputs": [],
      "source": [
        "system_python_prompt = \"\"\"\n",
        "You are an expert in extracting Python code from text. Your task is to identify and extract all Python code snippets within the given text.\n",
        "Please carefully locate any Python code, which may include functions, classes, variables, and other syntax, and extract it accurately.\n",
        "Do not add any additional text or explanation or any greeting, only provide the extracted Python code in its original format.\n",
        "\"\"\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "id": "3Peo-EfUL8lb"
      },
      "outputs": [],
      "source": [
        "def model_generation(system_prompt, user_prompt):\n",
        "\n",
        "  completion = client.chat.completions.create(\n",
        "      model=\"gpt-4o-mini\",\n",
        "      messages=[{\"role\":\"system\",\"content\": system_prompt}\n",
        "          ,{\"role\":\"user\", \"content\":user_prompt}]\n",
        "  )\n",
        "  return completion.choices[0].message.content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GYy686kaykRL"
      },
      "outputs": [],
      "source": [
        "\n",
        "def extracting_code_from_model_response(langage, response):\n",
        "    try:\n",
        "        match = re.search(rf\"```{langage}(.*?)```\", response, re.DOTALL)\n",
        "        if match:\n",
        "            return match.group(1).strip()\n",
        "        else:\n",
        "            raise ValueError(f\"No code {langage} found in the response.\")\n",
        "    except Exception as e:\n",
        "        return f\"Error: {str(e)}\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 136,
      "metadata": {
        "id": "3WDfx2nVsrTy"
      },
      "outputs": [],
      "source": [
        "def processus_extraction(code):\n",
        "\n",
        "  python_response = model_generation(system_python_prompt,code)\n",
        "  python_code = extracting_code_from_model_response(\"python\", python_response)\n",
        "\n",
        "  cpp_response = model_generation(system_cpp_prompt,python_code)\n",
        "  cpp_code = extracting_code_from_model_response('cpp', cpp_response)\n",
        "  markdown_cpp =  f\"```\\n{cpp_code}\\n```\"\n",
        "  return markdown_cpp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 645
        },
        "id": "RKERvicetfSt",
        "outputId": "fed4173e-306a-4222-cbfd-1f3d8de336da"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Running Gradio in a Colab notebook requires sharing enabled. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://e6d4c973f145d8df04.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div><iframe src=\"https://e6d4c973f145d8df04.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": []
          },
          "execution_count": 160,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\n",
        "\n",
        "backgroud_color = \".gradio-container {background-color: #f0f0f0;}\"\n",
        "with gr.Blocks(css=backgroud_color) as demo:\n",
        "\n",
        "  with gr.Row():\n",
        "    with gr.Column():\n",
        "      gr.Markdown(\"## Enter the python code here\")\n",
        "      code = gr.Textbox(label=\"Python code\")\n",
        "      greet_button = gr.Button(\"Greet\")\n",
        "\n",
        "\n",
        "    with gr.Column():\n",
        "      gr.Markdown(\"## C++ Code\")\n",
        "      output = [gr.Markdown()]\n",
        "\n",
        "\n",
        "  greet_button.click(fn=processus_extraction, inputs=[code], outputs=output)\n",
        "\n",
        "\n",
        "demo.launch()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gY2en6TK9UIE"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
